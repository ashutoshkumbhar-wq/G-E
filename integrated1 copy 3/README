1. Delete the .cache file and integrated1.py
2. the two pkl files are the gesture trained model files. they are called in zintegrated1copy.py
3. zintegrated1copy.py captures emotions and gestures 
4. zorchestrator_live takes the captured emotions and gestures and controls playback


HOW TO RUN

1. python3 -m pip install "numpy<2"
2. To run you need 4 files (2 .pkl files + zintegrated1copy.py + zorchestrator_live)
3. run zorchestrator_live directly from run button above in terminaly you can see realtime spotify status of which song is playing etc.
4. Now open new terminal and run zintegrated1copy.py (DONT RUN THIS BY PLAY BUTTON RUN THIS CODE BY PUTTING COMMAND TO RUN IN THE NEW TERMINAL)
5. Now choose the options in zintegrated terminal.
6. Check orechstrator terminal for status







IGNORE BELOW THIS 

# 1) See current numpy
python3 -c "import numpy as n; print(n.__version__)"

# 2) Downgrade NumPy to 1.x (safe pick)
python3 -m pip uninstall -y numpy
python3 -m pip install "numpy<2"  # installs 1.26.4 typically

# 3) Reinstall PyTorch to match (CPU is fine; Mac M-series works)
python3 -m pip install --upgrade --force-reinstall torch torchvision facenet-pytorch
# (If that errors, try CPU wheels:)
# python3 -m pip install --index-url https://download.pytorch.org/whl/cpu torch torchvision
# and then:
# python3 -m pip install facenet-pytorch
